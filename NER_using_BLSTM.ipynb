{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Building Deep Learning Models for Named Entity Recognition (NER) using PyTorch\n",
        "#### Time to run - Approximately 20 mins on GPU"
      ],
      "metadata": {
        "id": "oCkegxP7Vjki"
      },
      "id": "oCkegxP7Vjki"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.init as init\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence,pad_sequence\n",
        "import numpy as np\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.923954Z",
          "iopub.execute_input": "2023-03-28T04:30:39.924380Z",
          "iopub.status.idle": "2023-03-28T04:30:39.936498Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.924338Z",
          "shell.execute_reply": "2023-03-28T04:30:39.934945Z"
        },
        "trusted": true,
        "id": "YB73-4BjVjkm"
      },
      "execution_count": 1,
      "outputs": [],
      "id": "YB73-4BjVjkm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `make_sentences` reads the data and groups all words and labels for each sentence together. It returns a list of tuples in the structure `[(word, label), (word, label), ... , (word, label)]`.\n"
      ],
      "metadata": {
        "id": "wowSHvgtVjkn"
      },
      "id": "wowSHvgtVjkn"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_sentences(file_name):\n",
        "    train_data = []\n",
        "    with open(file_name,'r') as trainFile:\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in trainFile:\n",
        "            if line == '\\n':\n",
        "                train_data.append((words, labels))\n",
        "                words = []\n",
        "                labels = []\n",
        "            else:\n",
        "                index,word, label = line.strip().split()\n",
        "                words.append(word)\n",
        "                labels.append(label)\n",
        "    train_data.append((words,labels))\n",
        "    return train_data\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.939032Z",
          "iopub.execute_input": "2023-03-28T04:30:39.939753Z",
          "iopub.status.idle": "2023-03-28T04:30:39.950105Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.939682Z",
          "shell.execute_reply": "2023-03-28T04:30:39.948823Z"
        },
        "trusted": true,
        "id": "rhBp5kSBVjkn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rhBp5kSBVjkn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `get_word_count` returns two dictionaries: `count_dict` and `label_dict`. `count_dict` stores the count for every word, which is then used to remove words with occurrences less than a threshold value. `label_dict` is used only to get all unique labels.\n"
      ],
      "metadata": {
        "id": "C-XpaGiYVjko"
      },
      "id": "C-XpaGiYVjko"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_count(data):\n",
        "    count_dict = {}\n",
        "    label_dict = {}\n",
        "    for words, labels in data:\n",
        "        for word in words:\n",
        "            if word not in count_dict.keys():\n",
        "                count_dict[word] = 1\n",
        "            else:\n",
        "                count_dict[word]+=1\n",
        "        for label in labels:\n",
        "            if label not in label_dict.keys():\n",
        "                label_dict[label] = 1\n",
        "    return count_dict,label_dict\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.951714Z",
          "iopub.execute_input": "2023-03-28T04:30:39.952980Z",
          "iopub.status.idle": "2023-03-28T04:30:39.964498Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.952933Z",
          "shell.execute_reply": "2023-03-28T04:30:39.963466Z"
        },
        "trusted": true,
        "id": "sEIxWzfpVjko"
      },
      "execution_count": null,
      "outputs": [],
      "id": "sEIxWzfpVjko"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `get_word_embeddings` returns two dictionaries: `word_to_id` and `id_to_word`. `word_to_id` stores the index for every unique word, which is used for creating the vector that is fed into the model. `id_to_word` is used to retrieve the word from the model's prediction. I also define an `UNK_TOKEN` and a `PAD_TOKEN` index.\n"
      ],
      "metadata": {
        "id": "FvpJOKsnVjko"
      },
      "id": "FvpJOKsnVjko"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_embeddings(count_dict,UNK_TOKEN,PAD_TOKEN,threshold):\n",
        "    train_data = list(count_dict.keys())\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    word_to_id[UNK_TOKEN] = 0\n",
        "    id_to_word[0] = UNK_TOKEN\n",
        "\n",
        "    for word in train_data:\n",
        "        if word not in word_to_id.keys() and count_dict[word] > threshold:\n",
        "                id_to_word[len(word_to_id)] = word\n",
        "                word_to_id[word] = len(word_to_id)\n",
        "\n",
        "    id_to_word[len(word_to_id)] = PAD_TOKEN\n",
        "    word_to_id[PAD_TOKEN] = len(word_to_id)\n",
        "\n",
        "    return word_to_id,id_to_word\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.969168Z",
          "iopub.execute_input": "2023-03-28T04:30:39.969460Z",
          "iopub.status.idle": "2023-03-28T04:30:39.978350Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.969433Z",
          "shell.execute_reply": "2023-03-28T04:30:39.977166Z"
        },
        "trusted": true,
        "id": "Aol8srDAVjko"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Aol8srDAVjko"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `get_label_embeddings` performs a similar task as above. Instead of words, the inputs here are labels.\n"
      ],
      "metadata": {
        "id": "3MkrED9jVjkp"
      },
      "id": "3MkrED9jVjkp"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_embeddings(label_dict,PAD_TOKEN):\n",
        "    train_data = list(label_dict.keys())\n",
        "    label_to_id = {}\n",
        "    id_to_label = {}\n",
        "    for label in train_data:\n",
        "        if label not in label_to_id.keys():\n",
        "            id_to_label[len(label_to_id)] = label\n",
        "            label_to_id[label] = len(label_to_id)\n",
        "    id_to_label[len(label_to_id)] = PAD_TOKEN\n",
        "    label_to_id[PAD_TOKEN] = len(label_to_id)\n",
        "    return label_to_id, id_to_label\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.980706Z",
          "iopub.execute_input": "2023-03-28T04:30:39.981749Z",
          "iopub.status.idle": "2023-03-28T04:30:39.989537Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.981664Z",
          "shell.execute_reply": "2023-03-28T04:30:39.988444Z"
        },
        "trusted": true,
        "id": "_lyO67LbVjkp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_lyO67LbVjkp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "I create the training data and initialize the tokens below. A threshold of 1 means, It will consider all words that have occurred more than once. Out of all the models tried, the one with a threshold of 1 gave the best performance.\n"
      ],
      "metadata": {
        "id": "TmGSsq1TVjkp"
      },
      "id": "TmGSsq1TVjkp"
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = '/kaggle/input/dataset/data/train'\n",
        "valid_file = '/kaggle/input/dataset/data/dev'\n",
        "train_data = make_sentences(train_file)\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "threshold = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:39.991316Z",
          "iopub.execute_input": "2023-03-28T04:30:39.992662Z",
          "iopub.status.idle": "2023-03-28T04:30:40.368815Z",
          "shell.execute_reply.started": "2023-03-28T04:30:39.992621Z",
          "shell.execute_reply": "2023-03-28T04:30:40.367695Z"
        },
        "trusted": true,
        "id": "9uoWQeumVjkp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "9uoWQeumVjkp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dictionaries using the functions defined above."
      ],
      "metadata": {
        "id": "J0bVZ8mcVjkq"
      },
      "id": "J0bVZ8mcVjkq"
    },
    {
      "cell_type": "code",
      "source": [
        "count_dict = {}\n",
        "label_dict = {}\n",
        "word_to_id = {}\n",
        "label_to_id = {}\n",
        "id_to_word = {}\n",
        "id_to_label = {}\n",
        "\n",
        "count_dict,label_dict = get_word_count(train_data)\n",
        "word_to_id, id_to_word = get_word_embeddings(count_dict,UNK_TOKEN,PAD_TOKEN,threshold )\n",
        "label_to_id, id_to_label = get_label_embeddings(label_dict,PAD_TOKEN )\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.370305Z",
          "iopub.execute_input": "2023-03-28T04:30:40.371330Z",
          "iopub.status.idle": "2023-03-28T04:30:40.487266Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.371287Z",
          "shell.execute_reply": "2023-03-28T04:30:40.486111Z"
        },
        "trusted": true,
        "id": "hscjKJymVjkq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hscjKJymVjkq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `build_train_dataset` returns the training dataset ready to be fed into the model. It maps every word from the vocabulary to its index. If a word's count is below the threshold of 1, I map it to 0. Along with the words and labels, I also pass the real word list for each sentence, which is used to write files during prediction.\n"
      ],
      "metadata": {
        "id": "t_5YaA8BVjkq"
      },
      "id": "t_5YaA8BVjkq"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_train_dataset(train_data,word_to_id,label_to_id):\n",
        "    train_dataset = []\n",
        "    for words, labels in train_data:\n",
        "        wordlist = []\n",
        "        labellist = []\n",
        "        realword = []\n",
        "        for word in words:\n",
        "            realword.append(word)\n",
        "            if word not in word_to_id.keys():\n",
        "                wordlist.append(word_to_id['<UNK>'])\n",
        "            else:\n",
        "                wordlist.append(word_to_id[word])\n",
        "\n",
        "        for label in labels:\n",
        "            labellist.append(label_to_id[label])\n",
        "        train_dataset.append((torch.LongTensor(wordlist),torch.LongTensor(labellist),realword))\n",
        "    return train_dataset\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.489971Z",
          "iopub.execute_input": "2023-03-28T04:30:40.490737Z",
          "iopub.status.idle": "2023-03-28T04:30:40.499064Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.490663Z",
          "shell.execute_reply": "2023-03-28T04:30:40.497724Z"
        },
        "trusted": true,
        "id": "J0Gfklm1Vjkq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "J0Gfklm1Vjkq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `collate` function is used when loading dataloaders. For every batch, it pads the input words and labels. The padding size depends on the longest sequence in the batch. I use my padding index to determine the padding value.\n"
      ],
      "metadata": {
        "id": "0UQ0YKcwVjkq"
      },
      "id": "0UQ0YKcwVjkq"
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    inputs = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    realword = [item[2] for item in batch]\n",
        "    length = []\n",
        "    for item in batch:\n",
        "        length.append(len(item[0]))\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=len(word_to_id)-1)\n",
        "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=9)\n",
        "    length = torch.Tensor(length).int()\n",
        "    padded_inputs = padded_inputs.to(device)\n",
        "    padded_targets = padded_targets.to(device)\n",
        "    return padded_inputs, length, padded_targets,realword\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.502590Z",
          "iopub.execute_input": "2023-03-28T04:30:40.503187Z",
          "iopub.status.idle": "2023-03-28T04:30:40.513181Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.503141Z",
          "shell.execute_reply": "2023-03-28T04:30:40.511761Z"
        },
        "trusted": true,
        "id": "qym4HRZjVjkq"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qym4HRZjVjkq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the PyTorch DataLoader\n",
        "batch_size = 8\n",
        "train_dataset = build_train_dataset(train_data,word_to_id,label_to_id)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn,drop_last=True)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.519186Z",
          "iopub.execute_input": "2023-03-28T04:30:40.519488Z",
          "iopub.status.idle": "2023-03-28T04:30:40.936137Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.519460Z",
          "shell.execute_reply": "2023-03-28T04:30:40.934946Z"
        },
        "trusted": true,
        "id": "EZciFZ9eVjkr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "EZciFZ9eVjkr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the bidirectional LSTM model. The architecture of the model is as follows: Embedding → BLSTM → Linear → ELU → classifier. The parameters are defined as:\n",
        "- Embedding dimension: 100\n",
        "- Number of LSTM layers: 1\n",
        "- LSTM hidden dimension: 256\n",
        "- LSTM dropout: 0.33\n",
        "- Linear output dimension: 128\n",
        "\n",
        "The only additional feature in the model is weight initialization. After trying various methods, Xavier initialization gave the best results.\n"
      ],
      "metadata": {
        "id": "DL89LGDSVjkr"
      },
      "id": "DL89LGDSVjkr"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1233)\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx = word_to_id[PAD_TOKEN])\n",
        "        self.blstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.33)\n",
        "        self.linear = nn.Linear(hidden_dim * 2, 128)\n",
        "        self.activation = nn.ELU()\n",
        "        self.classifier = nn.Linear(128, output_dim)\n",
        "        # initialize weights of linear layer\n",
        "        init.xavier_uniform_(self.linear.weight)\n",
        "        init.zeros_(self.linear.bias)\n",
        "\n",
        "        # initialize weights of lstm layer\n",
        "        for name, param in self.blstm.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                init.xavier_uniform_(param)\n",
        "            elif 'bias' in name:\n",
        "                init.zeros_(param)\n",
        "\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        s = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n",
        "        outputs, _ = self.blstm(s)\n",
        "        s, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "        s = self.dropout(s)\n",
        "        linear_output = self.linear(s)\n",
        "        activation_output = self.activation(linear_output)\n",
        "        prediction = self.classifier(activation_output)\n",
        "\n",
        "        return prediction\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.938902Z",
          "iopub.execute_input": "2023-03-28T04:30:40.939213Z",
          "iopub.status.idle": "2023-03-28T04:30:40.953450Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.939182Z",
          "shell.execute_reply": "2023-03-28T04:30:40.951793Z"
        },
        "trusted": true,
        "id": "raY4EGTfVjkr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "raY4EGTfVjkr"
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the parameters for the model\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "dropout = 0.33\n",
        "blstm1 = BiLSTM(len(word_to_id), embedding_dim, hidden_dim, len(label_to_id), dropout)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 9)\n",
        "optimizer = torch.optim.SGD(blstm1.parameters(),lr = 0.9)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=14, gamma=0.5)\n",
        "blstm1 = blstm1.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.955537Z",
          "iopub.execute_input": "2023-03-28T04:30:40.956072Z",
          "iopub.status.idle": "2023-03-28T04:30:40.995280Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.956027Z",
          "shell.execute_reply": "2023-03-28T04:30:40.994109Z"
        },
        "trusted": true,
        "id": "AuzuzEJ9Vjkr"
      },
      "execution_count": null,
      "outputs": [],
      "id": "AuzuzEJ9Vjkr"
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "num_epochs = 23\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    pre_loss = float('inf')\n",
        "    blstm1.train()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        inputs,lengths, labels,realword = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = blstm1(inputs, lengths)\n",
        "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # I save the model only if the training loss in the current iteration is lower than the previous iteration\n",
        "    train_loss = train_loss/ len(train_loader)\n",
        "    if train_loss < pre_loss:\n",
        "        pre_loss = train_loss\n",
        "        torch.save(blstm1.state_dict(), 'blstm1.pt')\n",
        "\n",
        "    scheduler.step()\n",
        "    print(\"Epoch: \",epoch+1, \" Loss: \",train_loss)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:30:40.997328Z",
          "iopub.execute_input": "2023-03-28T04:30:40.997779Z",
          "iopub.status.idle": "2023-03-28T04:34:18.987449Z",
          "shell.execute_reply.started": "2023-03-28T04:30:40.997733Z",
          "shell.execute_reply": "2023-03-28T04:34:18.986259Z"
        },
        "trusted": true,
        "id": "OisifuGWVjks",
        "outputId": "4bc63b62-f986-4d97-cb55-f8b446d6ebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch:  1  Loss:  0.5002880737190948\nEpoch:  2  Loss:  0.2504637408752971\nEpoch:  3  Loss:  0.16017735704259517\nEpoch:  4  Loss:  0.11480645833717183\nEpoch:  5  Loss:  0.08844368781250983\nEpoch:  6  Loss:  0.07152367537546\nEpoch:  7  Loss:  0.05886797258144254\nEpoch:  8  Loss:  0.05100310852508245\nEpoch:  9  Loss:  0.042981528808318605\nEpoch:  10  Loss:  0.03630846395481501\nEpoch:  11  Loss:  0.036669236550931766\nEpoch:  12  Loss:  0.029804354210239473\nEpoch:  13  Loss:  0.027534459578828087\nEpoch:  14  Loss:  0.02313673351439886\nEpoch:  15  Loss:  0.017273899331148403\nEpoch:  16  Loss:  0.013459274439771764\nEpoch:  17  Loss:  0.012160614638177587\nEpoch:  18  Loss:  0.009805573573226641\nEpoch:  19  Loss:  0.00961612596136959\nEpoch:  20  Loss:  0.009301256132147709\nEpoch:  21  Loss:  0.008650588321013461\nEpoch:  22  Loss:  0.0075916284958447745\nEpoch:  23  Loss:  0.007192347489208993\n",
          "output_type": "stream"
        }
      ],
      "id": "OisifuGWVjks"
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model parameters\n",
        "blstm1.load_state_dict(torch.load('blstm1.pt'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:18.989346Z",
          "iopub.execute_input": "2023-03-28T04:34:18.989758Z",
          "iopub.status.idle": "2023-03-28T04:34:19.005662Z",
          "shell.execute_reply.started": "2023-03-28T04:34:18.989691Z",
          "shell.execute_reply": "2023-03-28T04:34:19.004361Z"
        },
        "trusted": true,
        "id": "JYR5v9VCVjks",
        "outputId": "ac8bb2e9-fdc3-4376-cc7e-99d6af9be0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "id": "JYR5v9VCVjks"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading and creating the valid Dataset for testing\n",
        "valid_data = make_sentences(valid_file)\n",
        "valid_dataset = build_train_dataset(valid_data,word_to_id,label_to_id)\n",
        "valid_loader =  DataLoader(valid_dataset, batch_size=1,collate_fn = collate_fn)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:19.007580Z",
          "iopub.execute_input": "2023-03-28T04:34:19.008020Z",
          "iopub.status.idle": "2023-03-28T04:34:19.142420Z",
          "shell.execute_reply.started": "2023-03-28T04:34:19.007977Z",
          "shell.execute_reply": "2023-03-28T04:34:19.141230Z"
        },
        "trusted": true,
        "id": "5obq1whJVjkt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5obq1whJVjkt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below generates the file used for evaluation. I use the official evaluation script `conll03eval` to evaluate the results of the model.\n"
      ],
      "metadata": {
        "id": "qALw4roJVjkt"
      },
      "id": "qALw4roJVjkt"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/working/dev1-perl.txt','w') as f:\n",
        "    blstm1.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,tags,realword) in valid_loader:\n",
        "\n",
        "            prediction = blstm1(sent,length)\n",
        "            sent = sent.tolist()\n",
        "            tags = tags.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "\n",
        "            i = 1\n",
        "            for (sent_ele,tag_ele,pred_ele) in zip(realword[0],tags[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[tag_ele]) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "            f.write(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:19.147796Z",
          "iopub.execute_input": "2023-03-28T04:34:19.148132Z",
          "iopub.status.idle": "2023-03-28T04:34:23.585112Z",
          "shell.execute_reply.started": "2023-03-28T04:34:19.148100Z",
          "shell.execute_reply": "2023-03-28T04:34:23.583980Z"
        },
        "trusted": true,
        "id": "5etKTG2cVjkt"
      },
      "execution_count": null,
      "outputs": [],
      "id": "5etKTG2cVjkt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code generates the .out file for Named Entity Recognition on the dev data.\n"
      ],
      "metadata": {
        "id": "NvBRD4GfVjkt"
      },
      "id": "NvBRD4GfVjkt"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/working/dev1.out','w') as f:\n",
        "    blstm1.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,tags,realword) in valid_loader:\n",
        "\n",
        "            prediction = blstm1(sent,length)\n",
        "            sent = sent.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "\n",
        "            i = 1\n",
        "            for (sent_ele,pred_ele) in zip(realword[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "            f.write(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:24.658359Z",
          "iopub.execute_input": "2023-03-28T04:34:24.658828Z",
          "iopub.status.idle": "2023-03-28T04:34:28.893265Z",
          "shell.execute_reply.started": "2023-03-28T04:34:24.658768Z",
          "shell.execute_reply": "2023-03-28T04:34:28.892142Z"
        },
        "trusted": true,
        "id": "KRw6kID9Vjku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "KRw6kID9Vjku"
    },
    {
      "cell_type": "code",
      "source": [
        "# creating sentences from the test file data\n",
        "test_file = '/kaggle/input/dataset/data/test'\n",
        "test_data = []\n",
        "with open(test_file,'r') as testFile:\n",
        "    words = []\n",
        "    for line in testFile:\n",
        "        if line == '\\n':\n",
        "            test_data.append((words))\n",
        "            words = []\n",
        "\n",
        "        else:\n",
        "            index,word = line.strip().split()\n",
        "            words.append(word)\n",
        "    test_data.append([word])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:28.894907Z",
          "iopub.execute_input": "2023-03-28T04:34:28.895298Z",
          "iopub.status.idle": "2023-03-28T04:34:28.939667Z",
          "shell.execute_reply.started": "2023-03-28T04:34:28.895256Z",
          "shell.execute_reply": "2023-03-28T04:34:28.938506Z"
        },
        "trusted": true,
        "id": "ZY9R_1TXVjku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZY9R_1TXVjku"
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding the test data sentences\n",
        "test_dataset = []\n",
        "for words in test_data:\n",
        "    wordlist = []\n",
        "    realword = []\n",
        "    for word in words:\n",
        "        realword.append(word)\n",
        "        if word not in word_to_id.keys():\n",
        "            wordlist.append(word_to_id['<UNK>'])\n",
        "        else:\n",
        "            wordlist.append(word_to_id[word])\n",
        "\n",
        "    test_dataset.append((torch.LongTensor(wordlist),realword))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:28.941742Z",
          "iopub.execute_input": "2023-03-28T04:34:28.942147Z",
          "iopub.status.idle": "2023-03-28T04:34:29.048447Z",
          "shell.execute_reply.started": "2023-03-28T04:34:28.942103Z",
          "shell.execute_reply": "2023-03-28T04:34:29.047155Z"
        },
        "trusted": true,
        "id": "RdTwXfZ3Vjku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "RdTwXfZ3Vjku"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the collate function for test data. The only difference here is we dont have labels. Rest everything remains the same as above."
      ],
      "metadata": {
        "id": "_3RC7PdXVjku"
      },
      "id": "_3RC7PdXVjku"
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_test(batch):\n",
        "    inputs = [item[0] for item in batch]\n",
        "    realword = [item[1] for item in batch]\n",
        "    length = []\n",
        "    for item in batch:\n",
        "        length.append(len(item[0]))\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=len(word_to_id)-1)\n",
        "    length = torch.Tensor(length).int()\n",
        "    padded_inputs = padded_inputs.to(device)\n",
        "    return padded_inputs, length,realword\n",
        "#Loading the test data with dataloader\n",
        "test_loader =  DataLoader(test_dataset, batch_size=1,collate_fn = collate_fn_test)\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:29.050402Z",
          "iopub.execute_input": "2023-03-28T04:34:29.051337Z",
          "iopub.status.idle": "2023-03-28T04:34:29.071373Z",
          "shell.execute_reply.started": "2023-03-28T04:34:29.051293Z",
          "shell.execute_reply": "2023-03-28T04:34:29.070245Z"
        },
        "trusted": true,
        "id": "ZOpVN-HUVjkv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZOpVN-HUVjkv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following snippet writes the required test file"
      ],
      "metadata": {
        "id": "pB9kTmSZVjkv"
      },
      "id": "pB9kTmSZVjkv"
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/working/test1.out','w') as f:\n",
        "    blstm1.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,realword) in test_loader:\n",
        "            prediction = blstm1(sent,length)\n",
        "            sent = sent.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "\n",
        "            i = 1\n",
        "            for (sent_ele,pred_ele) in zip(realword[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "            f.write(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:29.076376Z",
          "iopub.execute_input": "2023-03-28T04:34:29.076766Z",
          "iopub.status.idle": "2023-03-28T04:34:33.319156Z",
          "shell.execute_reply.started": "2023-03-28T04:34:29.076728Z",
          "shell.execute_reply": "2023-03-28T04:34:33.317973Z"
        },
        "trusted": true,
        "id": "Y6_8TAoVVjkv"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y6_8TAoVVjkv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In conclusion\n",
        "For task 1, after trying a lot of different hyperparameters I got an F1 score of 77% on the dev data. The precision is 80% and recall is about 74%"
      ],
      "metadata": {
        "id": "uNy9QOB7Vjkv"
      },
      "id": "uNy9QOB7Vjkv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TASK 2 - Using GloVe word embeddings to improve BLSTM"
      ],
      "metadata": {
        "id": "u4TJ8IrIVjkw"
      },
      "id": "u4TJ8IrIVjkw"
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading data from the train file and defining tokens\n",
        "train_file = '/kaggle/input/dataset/data/train'\n",
        "valid_file = '/kaggle/input/dataset/data/dev'\n",
        "train_data = make_sentences(train_file)\n",
        "PAD_TOKEN = '<PAD>'\n",
        "UNK_TOKEN = '<UNK>'\n",
        "threshold = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:33.320793Z",
          "iopub.execute_input": "2023-03-28T04:34:33.321172Z",
          "iopub.status.idle": "2023-03-28T04:34:33.693737Z",
          "shell.execute_reply.started": "2023-03-28T04:34:33.321130Z",
          "shell.execute_reply": "2023-03-28T04:34:33.692506Z"
        },
        "trusted": true,
        "id": "ZZjCORODVjkw"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZZjCORODVjkw"
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dictionaries\n",
        "count_dict = {}\n",
        "label_dict = {}\n",
        "word_to_id = {}\n",
        "label_to_id = {}\n",
        "id_to_word = {}\n",
        "id_to_label = {}\n",
        "\n",
        "count_dict,label_dict = get_word_count(train_data)\n",
        "word_to_id, id_to_word = get_word_embeddings(count_dict,UNK_TOKEN,PAD_TOKEN,threshold )\n",
        "label_to_id, id_to_label = get_label_embeddings(label_dict,PAD_TOKEN )\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:33.695877Z",
          "iopub.execute_input": "2023-03-28T04:34:33.696737Z",
          "iopub.status.idle": "2023-03-28T04:34:33.884378Z",
          "shell.execute_reply.started": "2023-03-28T04:34:33.696673Z",
          "shell.execute_reply": "2023-03-28T04:34:33.883041Z"
        },
        "trusted": true,
        "id": "UCya6XxIVjkx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "UCya6XxIVjkx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below creates a dictionary called `textEmbedding_glove`. It has the word as its key and the GloVe embeddings as its value.\n",
        "value"
      ],
      "metadata": {
        "id": "xrS-6utoVjkx"
      },
      "id": "xrS-6utoVjkx"
    },
    {
      "cell_type": "code",
      "source": [
        "textEmbedding_glove = {}\n",
        "i = 0\n",
        "with open('/kaggle/input/gloveembeddings/glove.6B.100d.txt','r') as gloveFile:\n",
        "        for line in gloveFile:\n",
        "            word = line.split()[0]\n",
        "            embedding = line.split()[1:]\n",
        "            embedding = np.array(embedding).astype('float64')\n",
        "            textEmbedding_glove[word] = embedding\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:34:33.886498Z",
          "iopub.execute_input": "2023-03-28T04:34:33.886920Z",
          "iopub.status.idle": "2023-03-28T04:35:01.820362Z",
          "shell.execute_reply.started": "2023-03-28T04:34:33.886876Z",
          "shell.execute_reply": "2023-03-28T04:35:01.819187Z"
        },
        "trusted": true,
        "id": "qb0twLPqVjkx"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qb0twLPqVjkx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code returns `gloveValues`, which we use as initial weights for the model. I first check if the word is capitalized, and if it is, whether the same word is covered by GloVe or not. If it is not covered, I embed the lowercase word. For any other word not covered by GloVe, I randomly initialize the values uniformly between -0.01 and 0.01. The embedding size is 100, as mentioned in the assignment.\n"
      ],
      "metadata": {
        "id": "jFCiwX4mVjky"
      },
      "id": "jFCiwX4mVjky"
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(129)\n",
        "gloveValues = []\n",
        "for word in word_to_id.keys():\n",
        "    lowercase_word = word.lower()\n",
        "    if lowercase_word in textEmbedding_glove.keys():\n",
        "\n",
        "        if word in textEmbedding_glove.keys():\n",
        "            gloveValues.append(textEmbedding_glove[word])\n",
        "        else:\n",
        "            gloveValues.append(textEmbedding_glove[lowercase_word])\n",
        "    else:\n",
        "        gloveValues.append(np.random.uniform(low=-0.01, high=0.01, size=100))\n",
        "\n",
        "gloveValues = np.array(gloveValues)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:01.822837Z",
          "iopub.execute_input": "2023-03-28T04:35:01.823751Z",
          "iopub.status.idle": "2023-03-28T04:35:01.865543Z",
          "shell.execute_reply.started": "2023-03-28T04:35:01.823703Z",
          "shell.execute_reply": "2023-03-28T04:35:01.864426Z"
        },
        "trusted": true,
        "id": "YeTRGrsxVjky"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YeTRGrsxVjky"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to build the training dataset. It also handles capitalization. I have introduced a list called `mask`, which is 1 if the letter is capitalized and 0 otherwise. I pass this mask list to the model.\n"
      ],
      "metadata": {
        "id": "XsNLT8woVjkz"
      },
      "id": "XsNLT8woVjkz"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_train_dataset_task2(train_data,word_to_id,label_to_id):\n",
        "    train_dataset = []\n",
        "    for words, labels in train_data:\n",
        "        wordlist = []\n",
        "        labellist = []\n",
        "        realword = []\n",
        "        mask = []\n",
        "        for word in words:\n",
        "            maskval = 0\n",
        "            for letter in word:\n",
        "                if letter.isupper():\n",
        "                    maskval = 1\n",
        "                    break\n",
        "            mask.append(maskval)\n",
        "            realword.append(word)\n",
        "            if word not in word_to_id.keys():\n",
        "                wordlist.append(word_to_id['<UNK>'])\n",
        "            else:\n",
        "                wordlist.append(word_to_id[word])\n",
        "\n",
        "        for label in labels:\n",
        "            labellist.append(label_to_id[label])\n",
        "        train_dataset.append((torch.LongTensor(wordlist),torch.LongTensor(labellist),realword,torch.LongTensor(mask)))\n",
        "    return train_dataset\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:01.867382Z",
          "iopub.execute_input": "2023-03-28T04:35:01.867858Z",
          "iopub.status.idle": "2023-03-28T04:35:01.877941Z",
          "shell.execute_reply.started": "2023-03-28T04:35:01.867810Z",
          "shell.execute_reply": "2023-03-28T04:35:01.876381Z"
        },
        "trusted": true,
        "id": "YmQYlKk4Vjkz"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YmQYlKk4Vjkz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is the collate function for Task 2. The only difference here is the addition of mask values. I also pad the values with 0 according to the longest sequence in the batch.\n"
      ],
      "metadata": {
        "id": "hgRs6Z1DVjkz"
      },
      "id": "hgRs6Z1DVjkz"
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_task2(batch):\n",
        "    inputs = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    realword = [item[2] for item in batch]\n",
        "    mask = [item[3] for item in batch]\n",
        "    length = []\n",
        "    for item in batch:\n",
        "        length.append(len(item[0]))\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=len(word_to_id)-1)\n",
        "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=9)\n",
        "    padded_mask =  pad_sequence(mask, batch_first=True, padding_value=0)\n",
        "    length = torch.Tensor(length).int()\n",
        "    padded_inputs = padded_inputs.to(device)\n",
        "    padded_targets = padded_targets.to(device)\n",
        "    padded_mask = padded_mask.to(device)\n",
        "    return padded_inputs, length, padded_targets,realword,padded_mask\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:01.885372Z",
          "iopub.execute_input": "2023-03-28T04:35:01.886328Z",
          "iopub.status.idle": "2023-03-28T04:35:01.896157Z",
          "shell.execute_reply.started": "2023-03-28T04:35:01.886292Z",
          "shell.execute_reply": "2023-03-28T04:35:01.894984Z"
        },
        "trusted": true,
        "id": "sr-dHeBbVjkz"
      },
      "execution_count": null,
      "outputs": [],
      "id": "sr-dHeBbVjkz"
    },
    {
      "cell_type": "code",
      "source": [
        "#Trraining data to be fecthed inside the model\n",
        "batch_size = 8\n",
        "train_dataset = build_train_dataset_task2(train_data,word_to_id,label_to_id)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn_task2,drop_last=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:01.897761Z",
          "iopub.execute_input": "2023-03-28T04:35:01.898360Z",
          "iopub.status.idle": "2023-03-28T04:35:02.401303Z",
          "shell.execute_reply.started": "2023-03-28T04:35:01.898316Z",
          "shell.execute_reply": "2023-03-28T04:35:02.400202Z"
        },
        "trusted": true,
        "id": "1Nqs5Ok7Vjkz"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1Nqs5Ok7Vjkz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model architecture is the same as in Task 1. The only difference here is the handling of capitalization.\n"
      ],
      "metadata": {
        "id": "cKTfvQlbVjkz"
      },
      "id": "cKTfvQlbVjkz"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "class NewBiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,padding_idx = word_to_id[PAD_TOKEN])\n",
        "        self.blstm = nn.LSTM(embedding_dim+1, hidden_dim, num_layers=1, bidirectional=True)\n",
        "        self.embedding.weight.data.copy_(torch.from_numpy(gloveValues))\n",
        "        self.dropout = nn.Dropout(0.33)\n",
        "        self.linear = nn.Linear(hidden_dim * 2, 128)\n",
        "        self.activation = nn.ELU()\n",
        "        self.classifier = nn.Linear(128, output_dim)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, text, lengths,masks):\n",
        "        embedded = self.embedding(text)\n",
        "        mask = torch.unsqueeze(masks, dim=2)\n",
        "        embednew =  torch.cat((embedded,mask),dim=2)\n",
        "        s = pack_padded_sequence(embednew, lengths, batch_first=True, enforce_sorted=False)\n",
        "        outputs, _ = self.blstm(s)\n",
        "        s, _ = pad_packed_sequence(outputs, batch_first=True)\n",
        "        s = self.dropout(s)\n",
        "        linear_output = self.linear(s)\n",
        "        activation_output = self.activation(linear_output)\n",
        "        prediction = self.classifier(activation_output)\n",
        "\n",
        "        return prediction\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:02.406329Z",
          "iopub.execute_input": "2023-03-28T04:35:02.406637Z",
          "iopub.status.idle": "2023-03-28T04:35:02.418359Z",
          "shell.execute_reply.started": "2023-03-28T04:35:02.406606Z",
          "shell.execute_reply": "2023-03-28T04:35:02.417051Z"
        },
        "trusted": true,
        "id": "dsK8qR2WVjk0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dsK8qR2WVjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing the parameters\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "dropout = 0.33\n",
        "blstm2 = NewBiLSTM(len(word_to_id), embedding_dim, hidden_dim, len(label_to_id), dropout)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 9)\n",
        "optimizer = torch.optim.SGD(blstm2.parameters(),lr = 0.1)\n",
        "scheduler1 = lr_scheduler.StepLR(optimizer, step_size=14, gamma=0.5)\n",
        "blstm2 = blstm2.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:02.421945Z",
          "iopub.execute_input": "2023-03-28T04:35:02.422384Z",
          "iopub.status.idle": "2023-03-28T04:35:02.454783Z",
          "shell.execute_reply.started": "2023-03-28T04:35:02.422348Z",
          "shell.execute_reply": "2023-03-28T04:35:02.453637Z"
        },
        "trusted": true,
        "id": "iYalBDXXVjk0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "iYalBDXXVjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "num_epochs = 86\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    pre_loss = float('inf')\n",
        "    blstm2.train()\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        inputs,lengths, labels,realword,mask = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = blstm2(inputs, lengths,mask)\n",
        "        outputs = outputs.reshape(-1, outputs.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_loss = train_loss/ len(train_loader)\n",
        "    if train_loss < pre_loss:\n",
        "        pre_loss = train_loss\n",
        "        torch.save(blstm2.state_dict(), 'blstm2.pt')\n",
        "\n",
        "\n",
        "    scheduler1.step()\n",
        "\n",
        "\n",
        "    print(\"Epoch: \",epoch, \" Loss: \",train_loss)\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:35:02.456390Z",
          "iopub.execute_input": "2023-03-28T04:35:02.456872Z",
          "iopub.status.idle": "2023-03-28T04:49:13.497486Z",
          "shell.execute_reply.started": "2023-03-28T04:35:02.456831Z",
          "shell.execute_reply": "2023-03-28T04:49:13.496201Z"
        },
        "trusted": true,
        "id": "nVebpkM0Vjk0",
        "outputId": "fafde5b0-f9eb-4443-a132-f3f860eb1f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch:  0  Loss:  0.39916226742078104\nEpoch:  1  Loss:  0.187626430999241\nEpoch:  2  Loss:  0.1325912398581522\nEpoch:  3  Loss:  0.11153483425154666\nEpoch:  4  Loss:  0.10042689911747307\nEpoch:  5  Loss:  0.09180080379118016\nEpoch:  6  Loss:  0.08543492293931187\nEpoch:  7  Loss:  0.07964268960933824\nEpoch:  8  Loss:  0.07601772577784512\nEpoch:  9  Loss:  0.0717917988959555\nEpoch:  10  Loss:  0.06759736507862396\nEpoch:  11  Loss:  0.06507494565735411\nEpoch:  12  Loss:  0.061725664948927735\nEpoch:  13  Loss:  0.058625030751644866\nEpoch:  14  Loss:  0.0556737042939451\nEpoch:  15  Loss:  0.05342360034658605\nEpoch:  16  Loss:  0.05168309015194484\nEpoch:  17  Loss:  0.05097128996161\nEpoch:  18  Loss:  0.0494417325696187\nEpoch:  19  Loss:  0.04848483345842913\nEpoch:  20  Loss:  0.04742912489016499\nEpoch:  21  Loss:  0.04647199210288725\nEpoch:  22  Loss:  0.04517862374541777\nEpoch:  23  Loss:  0.044052932706180416\nEpoch:  24  Loss:  0.04293764054552892\nEpoch:  25  Loss:  0.04193526163328558\nEpoch:  26  Loss:  0.04158393854308509\nEpoch:  27  Loss:  0.040093195099529716\nEpoch:  28  Loss:  0.038431237897585596\nEpoch:  29  Loss:  0.03828398566710005\nEpoch:  30  Loss:  0.03743537931553985\nEpoch:  31  Loss:  0.037246168075416565\nEpoch:  32  Loss:  0.036322146982261896\nEpoch:  33  Loss:  0.036077035933786236\nEpoch:  34  Loss:  0.03565145974096753\nEpoch:  35  Loss:  0.035082567115429404\nEpoch:  36  Loss:  0.034183519188322305\nEpoch:  37  Loss:  0.03424745107217123\nEpoch:  38  Loss:  0.03373221598250861\nEpoch:  39  Loss:  0.03362665272999615\nEpoch:  40  Loss:  0.03312676882153603\nEpoch:  41  Loss:  0.03258339315043491\nEpoch:  42  Loss:  0.03181829050665209\nEpoch:  43  Loss:  0.031242135820216583\nEpoch:  44  Loss:  0.03138573955004066\nEpoch:  45  Loss:  0.030978125592560513\nEpoch:  46  Loss:  0.03125388257661265\nEpoch:  47  Loss:  0.030910577739957427\nEpoch:  48  Loss:  0.030437037143307307\nEpoch:  49  Loss:  0.030094448621533116\nEpoch:  50  Loss:  0.030066809064318988\nEpoch:  51  Loss:  0.02997445712545859\nEpoch:  52  Loss:  0.029847615680457046\nEpoch:  53  Loss:  0.029205339205848065\nEpoch:  54  Loss:  0.0293361080649771\nEpoch:  55  Loss:  0.02946663269367088\nEpoch:  56  Loss:  0.028525947565287896\nEpoch:  57  Loss:  0.0281600332562713\nEpoch:  58  Loss:  0.02859613686474259\nEpoch:  59  Loss:  0.0285700522425083\nEpoch:  60  Loss:  0.0282397346623048\nEpoch:  61  Loss:  0.02781241015906355\nEpoch:  62  Loss:  0.02862240508164826\nEpoch:  63  Loss:  0.027848294350351053\nEpoch:  64  Loss:  0.028263182362194918\nEpoch:  65  Loss:  0.028043268725883735\nEpoch:  66  Loss:  0.027757983194786628\nEpoch:  67  Loss:  0.0274937852484011\nEpoch:  68  Loss:  0.02718905377614972\nEpoch:  69  Loss:  0.027323102160976515\nEpoch:  70  Loss:  0.027430110463246837\nEpoch:  71  Loss:  0.02737071199895956\nEpoch:  72  Loss:  0.026880765601070403\nEpoch:  73  Loss:  0.027046764594529333\nEpoch:  74  Loss:  0.027030593758773428\nEpoch:  75  Loss:  0.027281082458530698\nEpoch:  76  Loss:  0.02709327404575095\nEpoch:  77  Loss:  0.026784831773654302\nEpoch:  78  Loss:  0.026639204505944012\nEpoch:  79  Loss:  0.026885888130271457\nEpoch:  80  Loss:  0.02665707378169629\nEpoch:  81  Loss:  0.026679765378901054\nEpoch:  82  Loss:  0.026311896042479726\nEpoch:  83  Loss:  0.026657509444759305\nEpoch:  84  Loss:  0.02638544156344434\nEpoch:  85  Loss:  0.026415179275771514\n",
          "output_type": "stream"
        }
      ],
      "id": "nVebpkM0Vjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the model parameters\n",
        "blstm2.load_state_dict(torch.load('blstm2.pt'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:13.499107Z",
          "iopub.execute_input": "2023-03-28T04:49:13.499474Z",
          "iopub.status.idle": "2023-03-28T04:49:13.515598Z",
          "shell.execute_reply.started": "2023-03-28T04:49:13.499442Z",
          "shell.execute_reply": "2023-03-28T04:49:13.514417Z"
        },
        "trusted": true,
        "id": "AsjBoCV2Vjk0",
        "outputId": "4f416f32-5a85-47e1-86c9-a08523cceda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<All keys matched successfully>"
          },
          "metadata": {}
        }
      ],
      "id": "AsjBoCV2Vjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = make_sentences(valid_file)\n",
        "valid_dataset = build_train_dataset_task2(valid_data,word_to_id,label_to_id)\n",
        "valid_loader =  DataLoader(valid_dataset, batch_size=1,collate_fn = collate_fn_task2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:13.517417Z",
          "iopub.execute_input": "2023-03-28T04:49:13.517848Z",
          "iopub.status.idle": "2023-03-28T04:49:13.694917Z",
          "shell.execute_reply.started": "2023-03-28T04:49:13.517804Z",
          "shell.execute_reply": "2023-03-28T04:49:13.693738Z"
        },
        "trusted": true,
        "id": "lr5ey2HtVjk0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "lr5ey2HtVjk0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following is the code to generate the output, to be evaluated by the perl script."
      ],
      "metadata": {
        "id": "ueT_wPShVjk0"
      },
      "id": "ueT_wPShVjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "j =0\n",
        "with open('/kaggle/working/dev2-Perl.txt','w') as f:\n",
        "    blstm2.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,tags,realword,mask) in valid_loader:\n",
        "            prediction = blstm2(sent,length,mask)\n",
        "            sent = sent.tolist()\n",
        "            tags = tags.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "\n",
        "            i = 1\n",
        "            for (sent_ele,tag_ele,pred_ele) in zip(realword[0],tags[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[tag_ele]) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "\n",
        "            f.write(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:13.701055Z",
          "iopub.execute_input": "2023-03-28T04:49:13.701416Z",
          "iopub.status.idle": "2023-03-28T04:49:18.463076Z",
          "shell.execute_reply.started": "2023-03-28T04:49:13.701382Z",
          "shell.execute_reply": "2023-03-28T04:49:18.461816Z"
        },
        "trusted": true,
        "id": "rJLO1Oz5Vjk0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rJLO1Oz5Vjk0"
    },
    {
      "cell_type": "code",
      "source": [
        "#Generates the required dev file output\n",
        "j =0\n",
        "with open('/kaggle/working/dev2.out','w') as f:\n",
        "    blstm2.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,tags,realword,mask) in valid_loader:\n",
        "            prediction = blstm2(sent,length,mask)\n",
        "            sent = sent.tolist()\n",
        "            tags = tags.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "\n",
        "            i = 1\n",
        "            for (sent_ele,pred_ele) in zip(realword[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "\n",
        "            f.write(\"\\n\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:18.464814Z",
          "iopub.execute_input": "2023-03-28T04:49:18.465258Z",
          "iopub.status.idle": "2023-03-28T04:49:23.076808Z",
          "shell.execute_reply.started": "2023-03-28T04:49:18.465207Z",
          "shell.execute_reply": "2023-03-28T04:49:23.075642Z"
        },
        "trusted": true,
        "id": "pdQAgYRHVjk1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pdQAgYRHVjk1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Predictions on the Test Data"
      ],
      "metadata": {
        "id": "RhRfFESzkkNs"
      },
      "id": "RhRfFESzkkNs"
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating data from the test file\n",
        "test_file = '/kaggle/input/dataset/data/test'\n",
        "test_data = []\n",
        "with open(test_file,'r') as testFile:\n",
        "    words = []\n",
        "    for line in testFile:\n",
        "        if line == '\\n':\n",
        "            test_data.append((words))\n",
        "            words = []\n",
        "\n",
        "        else:\n",
        "            index,word = line.strip().split()\n",
        "            words.append(word)\n",
        "    test_data.append([word])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:23.078468Z",
          "iopub.execute_input": "2023-03-28T04:49:23.078895Z",
          "iopub.status.idle": "2023-03-28T04:49:23.119376Z",
          "shell.execute_reply.started": "2023-03-28T04:49:23.078852Z",
          "shell.execute_reply": "2023-03-28T04:49:23.118226Z"
        },
        "trusted": true,
        "id": "g05WD-qcVjk1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "g05WD-qcVjk1"
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = []\n",
        "for words in test_data:\n",
        "    wordlist = []\n",
        "    realword = []\n",
        "    mask = []\n",
        "    for word in words:\n",
        "        maskVal = 0\n",
        "        realword.append(word)\n",
        "        for letter in word:\n",
        "            if letter.isupper():\n",
        "                maskVal = 1\n",
        "        mask.append(maskVal)\n",
        "        if word not in word_to_id.keys():\n",
        "            wordlist.append(word_to_id['<UNK>'])\n",
        "        else:\n",
        "            wordlist.append(word_to_id[word])\n",
        "\n",
        "    test_dataset.append((torch.LongTensor(wordlist),realword,torch.LongTensor(mask)))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:23.121124Z",
          "iopub.execute_input": "2023-03-28T04:49:23.121553Z",
          "iopub.status.idle": "2023-03-28T04:49:23.247215Z",
          "shell.execute_reply.started": "2023-03-28T04:49:23.121509Z",
          "shell.execute_reply": "2023-03-28T04:49:23.246069Z"
        },
        "trusted": true,
        "id": "XEDg5BD7Vjk1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XEDg5BD7Vjk1"
    },
    {
      "cell_type": "code",
      "source": [
        "#Collate function for the test data\n",
        "def collate_fn_test2(batch):\n",
        "    inputs = [item[0] for item in batch]\n",
        "    realword = [item[1] for item in batch]\n",
        "    mask = [item[2] for item in batch]\n",
        "    length = []\n",
        "    for item in batch:\n",
        "        length.append(len(item[0]))\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=len(word_to_id)-1)\n",
        "    padded_masks= pad_sequence(mask, batch_first=True, padding_value=0)\n",
        "    length = torch.Tensor(length).int()\n",
        "    padded_inputs = padded_inputs.to(device)\n",
        "    padded_masks = padded_masks.to(device)\n",
        "    return padded_inputs, length,realword,padded_masks\n",
        "test_loader =  DataLoader(test_dataset, batch_size=1,collate_fn = collate_fn_test2)\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:23.249669Z",
          "iopub.execute_input": "2023-03-28T04:49:23.250991Z",
          "iopub.status.idle": "2023-03-28T04:49:23.268142Z",
          "shell.execute_reply.started": "2023-03-28T04:49:23.250944Z",
          "shell.execute_reply": "2023-03-28T04:49:23.266944Z"
        },
        "trusted": true,
        "id": "PI8YKK8lVjk1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "PI8YKK8lVjk1"
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the required test file output\n",
        "with open('/kaggle/working/test2.out','w') as f:\n",
        "    blstm2.eval()\n",
        "    with torch.no_grad():\n",
        "        for (sent, length,realword,mask) in test_loader:\n",
        "            prediction = blstm2(sent,length,mask)\n",
        "            sent = sent.tolist()\n",
        "            prediction = prediction.argmax(-1)\n",
        "            prediction = prediction.tolist()\n",
        "            i = 1\n",
        "            for (sent_ele,pred_ele) in zip(realword[0],prediction[0]):\n",
        "                string = str(i) + \" \" + str(sent_ele) + \" \" + str(id_to_label[pred_ele]) + \"\\n\"\n",
        "                f.write(string)\n",
        "                i+=1\n",
        "            f.write(\"\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:23.273436Z",
          "iopub.execute_input": "2023-03-28T04:49:23.273776Z",
          "iopub.status.idle": "2023-03-28T04:49:27.969613Z",
          "shell.execute_reply.started": "2023-03-28T04:49:23.273746Z",
          "shell.execute_reply": "2023-03-28T04:49:27.968506Z"
        },
        "trusted": true,
        "id": "ssLPM_KdVjk1"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ssLPM_KdVjk1"
    },
    {
      "cell_type": "code",
      "source": [
        "!perl /kaggle/input/conll03/conll03eval.txt < /kaggle/working/dev2-Perl.txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-28T04:49:27.971057Z",
          "iopub.execute_input": "2023-03-28T04:49:27.971447Z",
          "iopub.status.idle": "2023-03-28T04:49:29.421178Z",
          "shell.execute_reply.started": "2023-03-28T04:49:27.971409Z",
          "shell.execute_reply": "2023-03-28T04:49:29.419718Z"
        },
        "trusted": true,
        "id": "g5FCxAngVjk1",
        "outputId": "58983cd8-1cc1-4f69-95aa-cfc1d4a27993"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "processed 51578 tokens with 5942 phrases; found: 5908 phrases; correct: 5118.\naccuracy:  97.66%; precision:  86.63%; recall:  86.13%; FB1:  86.38\n              LOC: precision:  91.70%; recall:  90.20%; FB1:  90.94  1807\n             MISC: precision:  77.73%; recall:  81.78%; FB1:  79.70  970\n              ORG: precision:  78.61%; recall:  79.49%; FB1:  79.05  1356\n              PER: precision:  92.45%; recall:  89.09%; FB1:  90.74  1775\n",
          "output_type": "stream"
        }
      ],
      "id": "g5FCxAngVjk1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In conclusion\n",
        "I handle the capitalization criteria by create a new mask list as described above. The model returns an F1 score of 86.38% , precision: 86.63%, and recall: 86.13%"
      ],
      "metadata": {
        "id": "wsZc_eVzVjk2"
      },
      "id": "wsZc_eVzVjk2"
    }
  ]
}