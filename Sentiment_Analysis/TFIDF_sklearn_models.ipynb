{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzPgGM9D9dlc"
      },
      "source": [
        "# Sentiment Analysis Using Text Classification Techniques on Amazon Reviews Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfemq4a99dlg"
      },
      "source": [
        "- Libraries Used:  __Pandas, Contractions, Numpy, nltk, re, sklearn__\n",
        "- Time to Run the code: __Approximately 4 minutes__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeTw28WR9dlh",
        "outputId": "74a9ee61-d303-4365-b601-86f088eb5917"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/hetvishah/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/hetvishah/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /Users/hetvishah/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/hetvishah/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import contractions\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZoN9PTU9dlj"
      },
      "source": [
        "## Read Data\n",
        "The following cell reads the data.tsv file (available at [Amazon Reviews Dataset](https://www.kaggle.com/datasets/beaglelee/amazon-reviews-us-beauty-v1-00-tsv-zip)), stored in the working directory. Since the file data has a tabular structure, I have used a seperator to read it. I have also added an \"on_bad_lines\" parameter which handles any unstructured lines in the data by skipping it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa99GqTx9dlj",
        "outputId": "ac080308-ec9d-465f-9c8f-fd7a6c68d045"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/kk/j8krbbhd61779y9m_dwz846m0000gn/T/ipykernel_35011/1524444105.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataFile = pd.read_csv(r'data.tsv', sep='\\t', on_bad_lines = 'skip')\n"
          ]
        }
      ],
      "source": [
        "dataFile = pd.read_csv(r'data.tsv', sep='\\t', on_bad_lines = 'skip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kUl4tQu9dlk"
      },
      "source": [
        "## Keep Reviews and Ratings\n",
        "In the next cell, I am filtering the required columns for the analysis, namely: \"review_body\", \"review_headline\" and \"star_rating\". After carefully analyzing the \"star_rating\" column, I noticed some unwanted datetype strings. To clean that, I remove all the rows which are not numeric. Secondly, to make sure all the rows are of the same datatype, I am converting the columns, \"review_body\" and \"review_headline\" to string type.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YlxrvdP9dlk"
      },
      "outputs": [],
      "source": [
        "reducedDataFile = dataFile.filter(['review_body','review_headline','star_rating'])\n",
        "reducedDataFile = reducedDataFile[pd.to_numeric(reducedDataFile['star_rating'], errors='coerce').notnull()]\n",
        "reducedDataFile = reducedDataFile.astype({'star_rating':'int'})\n",
        "reducedDataFile = reducedDataFile.astype({'review_body':'str'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTXcQbYx9dll"
      },
      "source": [
        " ## We form three classes and select 20000 reviews randomly from each class.\n",
        "In the following as per the homework requirment, I am assigning \"classes\" to every review by its star rating. There are 3 classes with the distribution as:\n",
        "- Class 1 -> Star rating 1 and 2\n",
        "- Class 2 -> Star rating 3\n",
        "- Class 3 -> Star rating 4 and 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0E8cBzJ9dll"
      },
      "source": [
        "The function \"def Classes(x)\" returns a list with the belonging class as per the above requirement. I use the inbuild python assign function to convert the list into a dataframe column.\n",
        "Once the classes are created, the code downsamples the dataset and randomly selects 60K rows(20K from each class) for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES3qmI9k9dll"
      },
      "outputs": [],
      "source": [
        "def classes(x):\n",
        "    if x == 1 or x == 2:\n",
        "        temp = 1\n",
        "    elif x == 3:\n",
        "        temp = 2\n",
        "    else:\n",
        "        temp = 3\n",
        "    return temp\n",
        "tempClassList = []\n",
        "tempClassList = reducedDataFile['star_rating'].apply(classes)\n",
        "reviewDataFrame = reducedDataFile.assign(classes = tempClassList)\n",
        "reviewDataFrame = reviewDataFrame.groupby(['classes']).sample(n=20000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF7wZ0QZ9dll"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyvMS4ld9dlm"
      },
      "source": [
        "# Pre-processing\n",
        "For the preprocessing part, the snippet below is responsible to clean the \"review_body\" column. I have commented the meaning of every line below. An important observation in the cleaning process were the stop words removing many  negative words from the sentence. To avoid that, I tag the first instances of 3 negative words: no, not and never to NEGATE, NEG and NEGATIVE(Reference: https://reader.elsevier.com/reader/sd/pii/S1877050913001385?token=F183B53A28D401B590A6DD7C190DFCBBA1D4F045114C33277B8BB4789B7ADCB9B9514DF3AC285AADDD9D5B2932E4EB1D&originRegion=us-east-1&originCreation=20230125105004 ). It incorporates the negation of a sentence. I also observed that the stopword library contained words like: weren, haven, hasn etc showing negation. The contraction library used cannot fix these. Hence I am manually fixing these to its original meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GECZlWGM9dlm"
      },
      "outputs": [],
      "source": [
        "#Character count before preprocessing\n",
        "BeforeCleaning = sum(reviewDataFrame['review_body'].str.len())/len(reviewDataFrame['review_body'])\n",
        "\n",
        "#FOR REVIEW BODY\n",
        "#Tokenization\n",
        "\n",
        "#Convert reviews to lowercase\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.lower())\n",
        "#Remove any data inside brackets\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('\\[.*?\\]', '', x))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('\\(.*?\\)', '', x))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('\\{.*?\\}', '', x))\n",
        "#Remove web URL's from the reviews\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('https:\\/\\/.*', '', x))\n",
        "#Remove HTML tags\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('<[^<]+?>', '', x))\n",
        "#Remove words with numericals\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('\\w*\\d\\w*', '', x))\n",
        "#Remove '\\n' from the text. I noticed some text containing them.\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x:  re.sub('\\n', '', x))\n",
        "#Fix words like couldn't -> could not using the contraction library\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: contractions.fix(x))\n",
        "#Manually include the negative stopwords in a sentence\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" weren \", \" were not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" haven \", \" have not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" wouldn \", \" would not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" hasn \", \" has not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" shouldn \", \" should not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" hadn \", \" had not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" mightn \", \" might not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" couldn \", \" could not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" wasn \", \" was not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" needn \", \" need not \"))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" not \", \" NEG \",1))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" no \", \" NEGATE \",1))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: x.replace(\" never \", \" NEGATIVE \",1))\n",
        "#Removing Alphanumeric characters\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
        "#Removing any extra space\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: \" \".join(x.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TZdUMd-9dln"
      },
      "source": [
        "The snippet below cleans the \"review_headline\" column. Here I have not included the negative tags to keep the headline meaning intact since a headline is generally small. And to differentiate from review_body, I have converted all headlines into uppercase and contactinated them in review_body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRS6UbD59dln",
        "outputId": "ae02b256-0a1e-4604-e0be-c1daf14ad229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of reviews before cleaning:  269.00935\n",
            "Average length of reviews after cleaning:  277.7574833333333\n"
          ]
        }
      ],
      "source": [
        "#FOR REVIEW Headline\n",
        "\n",
        "#Data Preprocessing\n",
        "\n",
        "#Convert text to uppercase\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: x.upper())\n",
        "#remove words inside parenthesis\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('\\[.*?\\]', '', x))\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('\\(.*?\\)', '', x))\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('\\{.*?\\}', '', x))\n",
        "#remove web url's\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('https:\\/\\/.*', '', x))\n",
        "#Remove html tags\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('<[^<]+?>', '', x))\n",
        "#remove words containing numbers\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('\\w*\\d\\w*', '', x))\n",
        "#Remove '\\n'\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x:  re.sub('\\n', '', x))\n",
        "#Fix contracted words\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: contractions.fix(x))\n",
        "#Tag only three negative instances\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: x.replace(\" not \", \" NEG \",1))\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: x.replace(\" no \", \" NEGATE \",1))\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: x.replace(\" never \", \" NEGATIVE \",1))\n",
        "#Remove symbols\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: re.sub('[^a-zA-Z]', ' ', x))\n",
        "#Remove extra space\n",
        "reviewDataFrame['review_headline'] = reviewDataFrame['review_headline'].apply(lambda x: \" \".join(x.split()))\n",
        "\n",
        "#Concatinate two strings\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_headline'] + ' ' + reviewDataFrame['review_body']\n",
        "AfterCleaning = sum(reviewDataFrame['review_body'].str.len())/len(reviewDataFrame['review_body'])\n",
        "\n",
        "print(\"Average length of reviews before cleaning: \", BeforeCleaning)\n",
        "print(\"Average length of reviews after cleaning: \", AfterCleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j4VSkbw9dlo"
      },
      "source": [
        "There is an increase in words since I am concatinating review_headline to review_body. The word length might also have increased due to word-tagging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMZFfnwN9dlo"
      },
      "source": [
        "## remove the stop words\n",
        "Here using the nltk library inbuilt stopwords list, I remove all stopwords from the review. It helps getting rid of the common words and improved the accuracy as the review is no more dominated by those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwRHiolv9dlo"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "BeforePreprocessing = AfterCleaning\n",
        "filtered_words = set(stopwords.words('english'))\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: ' '.join([word for word in x.split() if word not in filtered_words]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w64xxdKa9dlp"
      },
      "source": [
        "## perform lemmatization  \n",
        "This snippet performs lemmatization. Here when directly using the lemmatizer library, we can only lemmatize nouns.\n",
        "For better pre-processing, I created a getPosTag function(Ref: StackOverflow). This function first tags the word in a sentence to verb, adjective, noun and adverb and returns the lemmating parameter. Once the words are tagged we can use the lemmatizer function to automatically lemmatize all these texts. After finishing lemmatization, I noticed some one and two lettered words which were still present in the reviews. These words were either a typing error, or something irrelevant to the review. And so I remove all the words from our review with length less than or equal to 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpzFHxSe9dlp",
        "outputId": "a6f9548e-31c3-4260-b5a7-b30f0706fc6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average length of reviews before pre-processing:  277.7574833333333\n",
            "Average length of reviews after pre-processing:  170.36905\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "def getPosTag(treebank_tag):\n",
        "\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "def lemmatize(token):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokenizedList = pos_tag(word_tokenize(token))\n",
        "    lemmStr = ''\n",
        "    for val in tokenizedList:\n",
        "        Tag = getPosTag(val[1])\n",
        "        if Tag!= '':\n",
        "            lemmStr+= ' '+ lemmatizer.lemmatize(val[0], Tag)\n",
        "        else:\n",
        "            lemmStr+= ' '+ val[0]\n",
        "    return lemmStr\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: lemmatize(x))\n",
        "\n",
        "\n",
        "#Remove tokens of length 1 or 2\n",
        "reviewDataFrame['review_body'] = reviewDataFrame['review_body'].apply(lambda x: ' '.join([word for word in x.split() if len(word) >= 3]))\n",
        "AfterPreprocessing = sum(reviewDataFrame['review_body'].str.len())/len(reviewDataFrame['review_body'])\n",
        "print(\"Average length of reviews before pre-processing: \", BeforePreprocessing)\n",
        "print(\"Average length of reviews after pre-processing: \", AfterPreprocessing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ykq5gP9dlp"
      },
      "source": [
        "# TF-IDF Feature Extraction\n",
        "TF-IDF is the last feature extraction process. Here I used the inbuilt train_test_split library to convert the data into test and training data, with 80% of the data being test data. Once converted, I create a TfidfVectorizer object and use it to create features for the model. The labels being the class rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ445phq9dlq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "trainingData, testingData , trainY, testY = train_test_split(reviewDataFrame['review_body'].values,reviewDataFrame['classes'].values,test_size=0.2,random_state=123, stratify = reviewDataFrame['classes'].values )\n",
        "vector = TfidfVectorizer()\n",
        "trainX = vector.fit_transform(trainingData)\n",
        "testX = vector.transform(testingData)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCJUPmm89dlr"
      },
      "source": [
        "Once we have the features and labels ready, we use four linear models to compare accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efxvvMt29dlr"
      },
      "source": [
        "# Perceptron\n",
        "\n",
        "Using the sklearn inbuilt perceptron model, the output here is as follows:\n",
        "- Class 1 precision, recall, f1-score\n",
        "- Class 2 precision, recall, f1-score\n",
        "- Class 3 precision, recall, f1-score\n",
        "- Avg Precision, Avg recall, Avg f1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1rqjOMn9dlr",
        "outputId": "6f2f4bf7-026f-449e-a1fb-df425ada0909"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.739521800281294 , 0.65725 , 0.6959629384513568\n",
            "0.6130250117980179 , 0.6495 , 0.6307356154406409\n",
            "0.7613501307344901 , 0.80075 , 0.7805531863043743\n",
            "0.7046323142712674 , 0.7025 , 0.702417246732124\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#alpha: Regularization term multiplier\n",
        "#eta0: Constant by which the updates are multiplied\n",
        "#n_iter_no_change: Number of iterations with no improvement to wait before early stopping\n",
        "#early_stopping: use early stopping to terminate training when validation score is not improving.\n",
        "modelPerceptron = Perceptron(random_state=0,alpha = 0.2,eta0 = 10,n_iter_no_change = 10,early_stopping=True)\n",
        "\n",
        "modelPerceptron.fit(trainX, trainY)\n",
        "accuracyPerceptron = modelPerceptron.score(testX,testY)\n",
        "Predictions = modelPerceptron.predict(testX)\n",
        "reportPerceptron = classification_report(testY,Predictions, digits=5, output_dict = True)\n",
        "\n",
        "print(reportPerceptron['1']['precision'],',',reportPerceptron['1']['recall'],',',reportPerceptron['1']['f1-score'])\n",
        "print(reportPerceptron['2']['precision'],',',reportPerceptron['2']['recall'],',',reportPerceptron['2']['f1-score'])\n",
        "print(reportPerceptron['3']['precision'],',',reportPerceptron['3']['recall'],',',reportPerceptron['3']['f1-score'])\n",
        "print(reportPerceptron['macro avg']['precision'],',',reportPerceptron['macro avg']['recall'],',', reportPerceptron['macro avg']['f1-score'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTE7dH-_9dls"
      },
      "source": [
        "# SVM\n",
        "Using the sklearn inbuilt linear SVM model with the \"hinge\" loss function, the output is as follows:\n",
        "- Class 1 precision, recall, f1-score\n",
        "- Class 2 precision, recall, f1-score\n",
        "- Class 3 precision, recall, f1-score\n",
        "- Avg Precision, Avg recall, Avg f1-score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQGfEgUq9dls",
        "outputId": "23ebdda2-51a5-4b1b-b9f5-beaa3e8871c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7569959339870844 , 0.79125 , 0.7737440410707738\n",
            "0.7166441136671178 , 0.662 , 0.6882391163092918\n",
            "0.8273520853540253 , 0.853 , 0.8399803052683408\n",
            "0.7669973776694091 , 0.7687500000000002 , 0.7673211542161354\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#tot: Tolerance for stopping criteria.\n",
        "# C: strength of the regularization is inversely proportional to C\n",
        "#intercept_scaling: increase the effect of regularization on synthetic feature weight (and therefore on the intercept).\n",
        "#max_iter: maximum number of passes over training data\n",
        "modelSVM = LinearSVC(loss  = 'hinge',tol = 1e-4, C = 0.7,intercept_scaling = 0.1, max_iter = 5000)\n",
        "\n",
        "modelSVM.fit(trainX, trainY)\n",
        "accuracySVM = modelSVM.score(testX,testY)\n",
        "PredictionsSVM = modelSVM.predict(testX)\n",
        "reportSVM = classification_report(testY,PredictionsSVM, digits=5, output_dict = True)\n",
        "\n",
        "print(reportSVM['1']['precision'],',',reportSVM['1']['recall'],',',reportSVM['1']['f1-score'])\n",
        "print(reportSVM['2']['precision'],',',reportSVM['2']['recall'],',',reportSVM['2']['f1-score'])\n",
        "print(reportSVM['3']['precision'],',',reportSVM['3']['recall'],',',reportSVM['3']['f1-score'])\n",
        "print(reportSVM['macro avg']['precision'],',',reportSVM['macro avg']['recall'],',', reportSVM['macro avg']['f1-score'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQkOGBo9dls"
      },
      "source": [
        "# Logistic Regression\n",
        "Using the sklearn inbuilt Logistic Regression model, and the \"saga\" solver, the output is as follows:\n",
        "- Class 1 precision, recall, f1-score\n",
        "- Class 2 precision, recall, f1-score\n",
        "- Class 3 precision, recall, f1-score\n",
        "- Avg Precision, Avg recall, Avg f1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL1gSR7v9dls",
        "outputId": "90b2a5c1-fe86-4488-d080-abde6ce97088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7647058823529411 , 0.78 , 0.7722772277227723\n",
            "0.7054322876817138 , 0.6915 , 0.6983966670874889\n",
            "0.8457114278569643 , 0.8455 , 0.8456057007125892\n",
            "0.7719498659638732 , 0.7723333333333334 , 0.7720931985076168\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "modelLR = LogisticRegression(tol = 1e-4, C = 0.8,solver = 'saga',max_iter=10000)\n",
        "modelLR.fit(trainX, trainY)\n",
        "accuracyLR = modelLR.score(testX,testY)\n",
        "PredictionsLR = modelLR.predict(testX)\n",
        "reportLR = classification_report(testY,PredictionsLR, digits=5, output_dict = True)\n",
        "print(reportLR['1']['precision'],',',reportLR['1']['recall'],',',reportLR['1']['f1-score'])\n",
        "print(reportLR['2']['precision'],',',reportLR['2']['recall'],',',reportLR['2']['f1-score'])\n",
        "print(reportLR['3']['precision'],',',reportLR['3']['recall'],',',reportLR['3']['f1-score'])\n",
        "print(reportLR['macro avg']['precision'],',',reportLR['macro avg']['recall'],',', reportLR['macro avg']['f1-score'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z5hADHK9dlt"
      },
      "source": [
        "# Naive Bayes\n",
        "Using the sklearn inbuilt Multinomial Naive Bayes model and hypertuning the alpha parameter, the output here is as follows:\n",
        "- Class 1 precision, recall, f1-score\n",
        "- Class 2 precision, recall, f1-score\n",
        "- Class 3 precision, recall, f1-score\n",
        "- Avg Precision, Avg recall, Avg f1-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IYKTviJ9dlt",
        "outputId": "12a58fd1-9413-4637-83fb-ef13bad6d160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7401613297482278 , 0.757 , 0.7484859720677296\n",
            "0.6492504409171076 , 0.73625 , 0.6900187441424555\n",
            "0.879632374740587 , 0.74175 , 0.8048284280482843\n",
            "0.7563480484686408 , 0.745 , 0.747777714752823\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "modelNB = MultinomialNB(alpha = 20)\n",
        "modelNB.fit(trainX, trainY)\n",
        "accuracyNB = modelNB.score(testX,testY)\n",
        "PredictionsNB = modelNB.predict(testX)\n",
        "reportNB = classification_report(testY,PredictionsNB, digits=5, output_dict = True)\n",
        "print(reportNB['1']['precision'],',',reportNB['1']['recall'],',',reportNB['1']['f1-score'])\n",
        "print(reportNB['2']['precision'],',',reportNB['2']['recall'],',',reportNB['2']['f1-score'])\n",
        "print(reportNB['3']['precision'],',',reportNB['3']['recall'],',',reportNB['3']['f1-score'])\n",
        "print(reportNB['macro avg']['precision'],',',reportNB['macro avg']['recall'],',', reportNB['macro avg']['f1-score'])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}